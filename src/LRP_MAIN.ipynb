{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense, Embedding, LSTM, Dropout, Activation\n",
    "from keras import backend as K\n",
    "from deepexplain.tensorflow import DeepExplain\n",
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "LSTM_MODEL_JSON = '../saved_model/model_lstm.json'\n",
    "LSTM_MODEL_WEIGHTS = '../saved_model/model_lstm.h5'\n",
    "HISTORY_FILE = '../saved_model/history_lstm.json'\n",
    "\n",
    "def save_lstm_model(model):\n",
    "    # load json and create model\n",
    "    model_json = model.to_json()\n",
    "    with open(LSTM_MODEL_JSON, 'w') as jsonfile:\n",
    "        jsonfile.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(LSTM_MODEL_WEIGHTS)\n",
    "\n",
    "def load_lstm_model(model):\n",
    "    # load weights into new model\n",
    "    loaded_model = model_from_json(LSTM_MODEL_JSON)\n",
    "    loaded_model.load_weights(LSTM_MODEL_WEIGHTS)\n",
    "    # evaluate loaded model on test data\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/final_data_less.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tokenizer()\n",
    "t.fit_on_texts(df['clean_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7051\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index)+1\n",
    "encoded_docs = t.texts_to_sequences(df['clean_sentiment'])\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.get_dummies(df['sentiment'].values)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "580\n"
     ]
    }
   ],
   "source": [
    "max_length = max([len(x) for x in encoded_docs])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "Training Shape:  (800, 580) == Train Lables:  (800, 2)\n",
      "Test Shape:  (200, 580) == Test Lables:  (200, 2)\n"
     ]
    }
   ],
   "source": [
    "split_fraction = 0.8\n",
    "split_idx = int(len(padded_docs)*split_fraction)\n",
    "print(split_idx)\n",
    "\n",
    "X_train, X_test = padded_docs[:split_idx], padded_docs[split_idx:]\n",
    "y_train, y_test = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "print(\"Training Shape: \", X_train.shape, \"== Train Lables: \", y_train.shape)\n",
    "print(\"Test Shape: \", X_test.shape, \"== Test Lables: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_session = K.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 580, 128)          902528    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 74240)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               7424100   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 202       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 8,326,830\n",
      "Trainable params: 8,326,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.8623 - acc: 0.5050 - val_loss: 0.6920 - val_acc: 0.5500\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 14s 17ms/step - loss: 0.6868 - acc: 0.5413 - val_loss: 0.6795 - val_acc: 0.5550\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.4376 - acc: 0.8125 - val_loss: 0.4826 - val_acc: 0.7550\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 13s 16ms/step - loss: 0.0389 - acc: 0.9925 - val_loss: 0.4949 - val_acc: 0.7600\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 12s 15ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.7750\n",
      "DeepExplain: running \"elrp\" explanation method (4)\n",
      "Model with multiple inputs:  False\n",
      "attributions shape --- (200, 580, 128)\n"
     ]
    }
   ],
   "source": [
    "with DeepExplain(session=current_session) as de:  # <-- init DeepExplain context\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,128,input_length=max_length))\n",
    "    model.add(Flatten());\n",
    "    model.add(Dense(100, activation='relu')); # input_shape=(max_words,)\n",
    "    model.add(Dropout(0.5));\n",
    "    model.add(Dense(2, activation='linear'));\n",
    "#     model.add(Dense(4, activation='linear'));\n",
    "    model.add(Activation('softmax'));\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy']);\n",
    "    print(model.summary());\n",
    "    model.fit(X_train, y_train,\n",
    "          batch_size=10,\n",
    "          epochs=5,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1,\n",
    "          shuffle=True);\n",
    "\n",
    "    # predict on test data\n",
    "    y_pred = model.predict(np.array(X_test));\n",
    "    y_test = np.array(y_test);\n",
    "    \n",
    "    # Evaluate the embedding tensor on the model input (in other words, perform the lookup)\n",
    "    embedding_tensor = model.layers[0].output\n",
    "    input_tensor = model.inputs[0]\n",
    "    embedding_out = current_session.run(embedding_tensor, {input_tensor: X_test});\n",
    "\n",
    "    xs = X_test;\n",
    "    ys = y_test;\n",
    "    # Run DeepExplain with the embedding as input\n",
    "    attributions = de.explain('elrp', model.layers[-2].output * ys, model.layers[1].input, embedding_out);\n",
    "    print(\"attributions shape --- {}\".format(attributions.shape));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_lstm_model(model)\n",
    "# model = load_lstm_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.50%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions.shape\n",
    "np.save('att.npy', attributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.load('att.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_TEST = '../data/test_less.csv'\n",
    "def get_test_sentence(sent_idx):\n",
    "    \"\"\"\n",
    "    Returns a test set sentence and its label, sent_idx must be an integer in [1, 2210]\"\"\"\n",
    "    _df = pd.read_csv(SEQUENCE_TEST)\n",
    "    print(\"Shape: \",_df.shape)\n",
    "#     sentence = _df['reviewText'][sent_idx]\n",
    "#     print(\"Raw Sentiment\\n\")\n",
    "#     print(sentence)\n",
    "    sentiment = _df['sentiment'][sent_idx]\n",
    "    sentence_ = _df['clean_sentiment'][sent_idx]\n",
    "    sent_array = y_test[sent_idx]\n",
    "    print(\"Clean Texts:\\n\")\n",
    "    print(sentence_)\n",
    "    print(\"Sentiment: \", sentiment)\n",
    "    clean_words = sentence_.split()\n",
    "    return clean_words, sentiment\n",
    "\n",
    "def find_score(sent_idx):\n",
    "    sent_words, sent_sentiment = get_test_sentence(sent_idx)\n",
    "    scores = []\n",
    "    for idx, word in enumerate(sent_words):\n",
    "        print(word, \": \", b[sent_idx][idx].sum())\n",
    "        scores.append(b[sent_idx][idx].sum())\n",
    "    scores = np.array(scores)\n",
    "    return sent_words, scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (200, 3)\n",
      "Clean Texts:\n",
      "\n",
      "got 3m old son although seem fit body fine wasnt able sit without assistance thought 5th month probably wont fit body practical also long height seem like tip easily even straps didnt feel comfortable using without supervises would recommend\n",
      "Sentiment:  0\n"
     ]
    }
   ],
   "source": [
    "sent_words, sent_sentiment = get_test_sentence(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.heatmap import html_heatmap\n",
    "\n",
    "import codecs\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (200, 3)\n",
      "Clean Texts:\n",
      "\n",
      "got 3m old son although seem fit body fine wasnt able sit without assistance thought 5th month probably wont fit body practical also long height seem like tip easily even straps didnt feel comfortable using without supervises would recommend\n",
      "Sentiment:  0\n",
      "got :  -0.05375789\n",
      "3m :  0.037802503\n",
      "old :  -0.24430352\n",
      "son :  -0.29903167\n",
      "although :  0.080530465\n",
      "seem :  0.00020494871\n",
      "fit :  -0.05892004\n",
      "body :  -0.047177978\n",
      "fine :  0.15070361\n",
      "wasnt :  -0.021080611\n",
      "able :  -0.1420303\n",
      "sit :  0.07942906\n",
      "without :  -0.3722966\n",
      "assistance :  0.040475845\n",
      "thought :  0.26360533\n",
      "5th :  0.0012445571\n",
      "month :  0.043012396\n",
      "probably :  0.07722144\n",
      "wont :  0.05125931\n",
      "fit :  0.12899534\n",
      "body :  -0.072885126\n",
      "practical :  0.06041016\n",
      "also :  -0.087189354\n",
      "long :  -0.02296719\n",
      "height :  -0.1245781\n",
      "seem :  -0.14926124\n",
      "like :  -0.05637505\n",
      "tip :  -0.11973221\n",
      "easily :  -0.010592928\n",
      "even :  -0.040554233\n",
      "straps :  0.026007628\n",
      "didnt :  -0.0029238444\n",
      "feel :  -0.0011834865\n",
      "comfortable :  -0.0707767\n",
      "using :  0.03204188\n",
      "without :  -0.03337615\n",
      "supervises :  -0.006357707\n",
      "would :  0.094616964\n",
      "recommend :  0.060885005\n"
     ]
    }
   ],
   "source": [
    "words_, scores_ = find_score(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.3757891e-02,  3.7802503e-02, -2.4430352e-01, -2.9903167e-01,\n",
       "        8.0530465e-02,  2.0494871e-04, -5.8920041e-02, -4.7177978e-02,\n",
       "        1.5070361e-01, -2.1080611e-02, -1.4203030e-01,  7.9429060e-02,\n",
       "       -3.7229660e-01,  4.0475845e-02,  2.6360533e-01,  1.2445571e-03,\n",
       "        4.3012396e-02,  7.7221438e-02,  5.1259309e-02,  1.2899534e-01,\n",
       "       -7.2885126e-02,  6.0410161e-02, -8.7189354e-02, -2.2967190e-02,\n",
       "       -1.2457810e-01, -1.4926124e-01, -5.6375049e-02, -1.1973221e-01,\n",
       "       -1.0592928e-02, -4.0554233e-02,  2.6007628e-02, -2.9238444e-03,\n",
       "       -1.1834865e-03, -7.0776701e-02,  3.2041881e-02, -3.3376150e-02,\n",
       "       -6.3577071e-03,  9.4616964e-02,  6.0885005e-02], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:#dadaff\">got</span> <span style=\"background-color:#ffe6e6\">3m</span> <span style=\"background-color:#5858ff\">old</span> <span style=\"background-color:#3232ff\">son</span> <span style=\"background-color:#ffc8c8\">although</span> <span style=\"background-color:#fffefe\">seem</span> <span style=\"background-color:#d6d6ff\">fit</span> <span style=\"background-color:#dedeff\">body</span> <span style=\"background-color:#ff9898\">fine</span> <span style=\"background-color:#f0f0ff\">wasnt</span> <span style=\"background-color:#9e9eff\">able</span> <span style=\"background-color:#ffc8c8\">sit</span> <span style=\"background-color:#0000ff\">without</span> <span style=\"background-color:#ffe4e4\">assistance</span> <span style=\"background-color:#ff4949\">thought</span> <span style=\"background-color:#fffefe\">5th</span> <span style=\"background-color:#ffe2e2\">month</span> <span style=\"background-color:#ffcaca\">probably</span> <span style=\"background-color:#ffdcdc\">wont</span> <span style=\"background-color:#ffa6a6\">fit</span> <span style=\"background-color:#ccccff\">body</span> <span style=\"background-color:#ffd6d6\">practical</span> <span style=\"background-color:#c3c3ff\">also</span> <span style=\"background-color:#f0f0ff\">long</span> <span style=\"background-color:#aaaaff\">height</span> <span style=\"background-color:#9898ff\">seem</span> <span style=\"background-color:#d8d8ff\">like</span> <span style=\"background-color:#acacff\">tip</span> <span style=\"background-color:#f8f8ff\">easily</span> <span style=\"background-color:#e3e3ff\">even</span> <span style=\"background-color:#ffeeee\">straps</span> <span style=\"background-color:#fcfcff\">didnt</span> <span style=\"background-color:#fefeff\">feel</span> <span style=\"background-color:#ceceff\">comfortable</span> <span style=\"background-color:#ffe8e8\">using</span> <span style=\"background-color:#e8e8ff\">without</span> <span style=\"background-color:#fafaff\">supervises</span> <span style=\"background-color:#ffbebe\">would</span> <span style=\"background-color:#ffd6d6\">recommend</span> \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(html_heatmap(words_, scores_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
